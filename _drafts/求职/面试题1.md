

3. 如何防止缓存穿透？如何加锁？可否用本地锁

4. cpu报表了怎么办？

5. Memory报表了怎么办

6. 死锁问题

7. go gc优化

8. 分库分表怎么实现，怎么处理共享表的？

9. 简历亮点： 别人没做的我在做； 项目的规模，业务的背景，项目的效果，个人的成绩 3～5个项目

# http


## 谷歌二面：浏览器和服务器之间的双向通信只能选 Websocket 吗 ？其他的行不行？为什么 ？
- http是单向的

- websocket是双向的
浏览器->服务器: Upgrade: WebSocket
服务器->浏览器: 101 Switch Protocols
浏览器->服务器: Web Socket数据
服务器->浏览器: Web Socket数据
服务器->浏览器:Web Socket数据

- sse
发送一个消息个chatgpt
F12->网络，查看POST请求Content-Type:text/event-stream

浏览器->服务器: 
服务器->浏览器: 
服务器->浏览器: 
服务器->浏览器: 

## http2
1. 多路复用
2. 首部压缩
3. 服务端推送

## jwt

传统的Cookie和Session模式：
- 横向扩展困难；
- 如果使用redis，那么会严重依赖外部且加重了网络开销
- Cookie是可以被篡改的，重要信息不能依赖Cookie

jwt包含了三部分：

header: 算法 + 令牌类型
payload: 七个默认字段：发行人，到期时间，主题，用户，nbf在某个时间段不可用，不可用，jwt-id，此外可以自定义字段
signature: 前面两部分加密后签名

jwt的劣势？
- 它不会保留服务端状态，无法强制用户下线
- 他是不加密的，不要放敏感信息（只是base64了一下
- 占用header空间大

# nginx

## 性能优化
1. 开启http2
2. 开启数据压缩 （常用gzip，或者brotli）
3. 调整nginx的连接数和线程数 worker_processes(工作进程设置为cpu核数)和worker_connections（单个工作进程可以负责的连接数）

# mysql 
## 自增主键不唯一的情况 （原因就是这个自增值是不会会滚的
（1）唯一键冲突（导致了rollback
（2）事务回滚 
（3）批量插入数据 （批量申请自增ID策略，用不完的也不回收掉
## 间隙锁
就是两个值之间的空隙加锁，是Innodb在可重复隔离级别下为了解决幻读问题而引入的一种锁机制。需要注意，间隙锁只会在可重复读隔离级别。

总结：他可以锁定一个范围内的所有记录（包括还没有创建出来的记录），并且不包含边界值，从而防止其他事务在这个范围内插入或者修改记录


## mysql 添加索引不会锁表吗
5.5以及以前的版本，通常修改数据表结构的操作（DDL）会阻塞对数据
mysql5.6提供online DD之后，可以同时进行DDL和DML操作，降低了DDL期间对业务延迟带来的影响

1. 一般的DDL语句测试如下：他有两个加锁的过程，一旦元数据锁被占用，就会被阻塞，只有其他事务释放了锁，他才回继续进行
（意思是他会锁表，但是不会影响读写，别的读或者写请求来了能继续执行）

测试，在一个客户端中执行如下命令，注意，不要提交
```sql
begin
select * from scores where id = 1
```

在另一个客户端中执行如下命令，会发现他卡住了，通过show processlist会看到他在等待元数据锁（上面的读查询占用了）
```sql
begin;
ALTER TABLE scores ADD index idx_student_id(student_id);
commit;
```

在第一个客户端commit之后，表结构变更终于成功了。

2. OnLine DDL语句

```sql
begin;
ALTER TABLE scores ADD index idx_student_id(student_id),ALGORITHM=INPLACE, LOCK=NONE;
commit;
```

ALGORITHM:
- DEFAULT 默认算法，使用最高效的算法, 
- INPLACE 在原表上进行修改，不需要生成临时表，不需要进行数据copy的过程
- COPY 5.6之前的方式
LOCK:
- DEFAULT, 默认方式，由mysql自行判断使用哪种方式，尽量不锁表
- NONE，与INPLACE方式搭配使用。允许ONLINE DDL期间进行并发读写操作。
- SHARED，共享锁，ONLINE DDL期间阻塞写入，不影响读取
- EXCLUSIVE，拍他锁，Online DDL期间不允许对锁表进行任何操作


## 索引下推
https://www.cnblogs.com/three-fighter/p/15246577.html

索引下推(Index Condition Pushdown，简称ICP)，是MySQL5.6版本的新特性，它能减少回表查询次数，提高查询效率。

MySQL服务层负责SQL语法解析、生成执行计划等，并调用存储引擎层去执行数据的存储和检索。索引下推的下推其实就是指将部分上层（服务层）负责的事情，交给了下层（引擎层）去处理。

在没有使用ICP的情况下，MySQL的查询：

存储引擎读取索引记录；
根据索引中的主键值，定位并读取完整的行记录；
存储引擎把记录交给Server层去检测该记录是否满足WHERE条件。

使用ICP的情况下，查询过程：

存储引擎读取索引记录（不是完整的行记录）；
判断WHERE条件部分能否用索引中的列来做检查，条件不满足，则处理下一行索引记录；
条件满足，使用索引中的主键去定位并读取完整的行记录（就是所谓的回表）；
存储引擎把记录交给Server层，Server层检测该记录是否满足WHERE条件的其余部分。

索引下推使用条件

- 只能用于range、 ref、 eq_ref、ref_or_null访问方法；
- 只能用于InnoDB和 MyISAM存储引擎及其分区表；
- 对InnoDB存储引擎来说，索引下推只适用于二级索引（也叫辅助索引）;
> 索引下推的目的是为了减少回表次数，也就是要减少IO操作。对于InnoDB的聚簇索引来说，数据和索引是在一起的，不存在回表这一说。
此外
引用了子查询的条件不能下推；
引用了存储函数的条件不能下推，因为存储引擎无法调用存储函数。


## 为什么使用limit翻页查询，越来越慢
select * from table limit 10000,10
执行这句的逻辑是
（1）从数据表中读取N条数据到数据集中
（2）重复上一步到第10000 + 10
（3）根据offset抛弃前面的10000条数据  
（4）返回剩余的10条数据

优化
（1）通过自增id或其他可寻址字段查到那10条
（2）如果没有条件使用方法（1），那么可以 “先查找出需要数据的索引列（假设为id），再通过索引列查找这10条数据”
select * from table where id in (select id where xxxxxx)
（3）如果能做到（2），那么还可以做一次优化，使用表连接，而不是使用in
（4）直接不允许用户跳转到100## 常用优化手段
1. 不要用select * （1）查询了无用的字段，浪费了资源 （2）容易导致不走覆盖索引 （3）字段变更
2. 小表驱动大表 n * logM。小表可以一次性加载到在join buffer中，BNL（Block Nested Loop）友好；而大表需要分阶段加载进去。selec xxx from 主表 left join on 非主表 on 
3. 提升group by执行效率。比如给group by字段加索引
4. 批量插入取代逐条插入，逐条插入每次都会请求数据库
5. 数据量太大的话使用limit，分页查询
6. 使用union all而不是union，前者不去重， 如果要去重的话，尽量使用索引
7. join的表不宜过多
（1）查询效率下降，可以冗余关联字段来减少表的连接，进而减少扫描量
（2）系统负载增大
（3）维护难度增大，在一个表中连接了多个表的查询，如果要修改其中一个表的结构或者内容，那么以后维护困难（比如要分库分表）


## 加了唯一索引之后，还会遇到重复记录吗

联合唯一索引(id, course),其中course varchar(10) null.
那么 可以存在两条一样的记录 (1, null), (1, null)。 因为对于计算机来说两个null是不一样的。

比较的结果是三个：true，false，未知。在mysql中，任何于null比较的结果都是未知的。

1. 逻辑删除问题
id 是唯一索引
```sql
delete from `student` where id = 123;
update `student` set delete_status = 1 where id = 123;
```
如果再添加一个id=123，就会有问题， 这时候怎么办？

加一个delete_id

唯一索引改为 （id， delete_status, delete_id）. 删除数据时候同时设置delete_status和delete_id, 

只加一个delete_at可否？也可以，但是过滤查询时没法等值比较；delete_status和delete_id还能做数据恢复等

## 性能优化
1. 选择正确的存储引擎。事务->innodb；更新少：myisam
2. 优化查询；explain查询计划;开启慢查询（默认关闭，有性能代价）；
3. 避免索引失效
4. 避免使用select *， 减少不必要的字段
5. 使用索引覆盖，避免回表
6. limit
7. 使用最小数据类型，比如说IP，不要用字符串。使用int（4字节）定长的

## 为什么MySQL单表不能超过2000万行
- 假设主键是bigint类型，8字节。，页号4字节。每个页16K大小。
- 掐头去尾，一个非叶子结点页面最多目录项数：15k / 12byte = 1280
- 假设行数据位1k，那么一个叶子结点存放数据15行
- 假设b+树是3层的，那么 1280 * 1280 * 15 = 24576000个数据
- 如果b+数是4层的，那么数据量就大的离谱了，可能之前就分库分表了。
## InnoDB系统自增row_id
如果你创建的 InnoDB 表没有指定主键，那么 InnoDB 会给你创建一个不可见的，长度为 6 个字节的 row_id。InnoDB 维护了一个全局的 dict_sys.row_id 值，所有无主键的 InnoDB 表，每插入一行数据，都将当前的 dict_sys.row_id 值作为要插入数据的 row_id，然后把 dict_sys.row_id 的值加 1。

实际上，在代码实现时 row_id 是一个长度为8字节的无符号长整型 (bigint unsigned)。但是，InnoDB 在设计时，给 row_id 留的只是 6 个字节的长度，这样写到数据表中时只放了最后 6 个字节，所以 row_id 能写到数据表中的值，就有两个特征：

row_id 写入表中的值范围，是从 0 到 248-1；
当 dict_sys.row_id=2^48时，如果再有插入数据的行为要来申请 row_id，拿到以后再取最后 6 个字节的话就是 0。

## mysql数据库cpu飙升怎么办？
排查：
- 用top命令观察，确定是mysqld导致的还是其他原因
- 如果是mysqld导致的，show processlist，查看session情况，确定是不是有消耗资源的sql在运行
- 找出消耗高的sql，看看执行计划是否准确，索引是否缺失，数据量是否太大
处理：
- kill掉这些线程（同时观察cpu使用率是否下降）
- 进行相应的调整（比如说加索引，修改sql，改内存参数等）
- 重新跑这些sql

## 自增主键用完了怎么办？

> “这问题没遇到过，因为自增主键一般用int类型，一般达不到最大值，我们就分库分表了，所以不曾遇见过！”

在mysql中，unsigned int的范围如下 （0～4294967295），4字节。一旦自增id达到最大值，此时数据继续插入是会报一个主键冲突异常如下所示

```sh
Duplicate entry '4294967295' for key 'PRIMARY'
```

那解决方法也是很简单的，将Int类型改为BigInt类型，BigInt的范围(0~18446744073709551615), 将自增ID设为BigInt类型，你是不用考虑自增ID达到最大值这个问题.

进一步提问，如何修改数据类型？

方案一：直接修改
在5.6+开始，mysql支持在线修改数据库表，在修改表的过程中，对绝大部分操作，原表可读，也可以写。那对于修改列的数据类型这种操作，原表还能写么？

答：对于修改数据类型这种操作，是不支持并发的DML操作！也就是说，如果你直接使用ALTER这样的语句在线修改表数据结构，会导致这张表无法进行更新类操作(DELETE、UPDATE、DELETE)。

因此，直接ALTER是不行滴！

方案二：借助第三方工具

1. pt-online-schema-chang，简称pt-osc
- 创建一个新的表，表结构为修改后的数据表，用于从源数据表向新表中导入数据。
- 创建触发器，用于记录从拷贝数据开始之后，对源数据表继续进行数据修改的操作记录下来，用于数据拷贝结束后，执行这些操作，保证数据不会丢失。
- 拷贝数据，从源数据表中拷贝数据到新表中。
- ename源数据表为old表，把新表rename为源表名，并将old表删除。
- 删除触发器。
2. GitHub正式宣布以开源的方式发布的工具，名为gh-ost

## 自增id的生成时机
生成自增 ID 的过程是在 MySQL 的存储引擎层进行的。对于使用 InnoDB 存储引擎的表，MySQL 会使用自增锁（auto-increment locking）机制来保证生成的自增 ID 的唯一性。在插入数据时，InnoDB 会获取自增锁，生成一个新的自增 ID，并将其分配给插入的数据行。然后，在事务提交或回滚时，自增锁会被释放，下一个插入操作可以继续生成下一个自增 ID。

需要注意的是，自增 ID 的生成是在存储引擎层完成的，并不是 MySQL 服务器层的功能。因此，不同的存储引擎可能会在自增 ID 的生成和管理上有所不同。例如，MyISAM 存储引擎使用表级锁来生成自增 ID，而 InnoDB 存储引擎使用自增锁来生成自增 ID。

总结起来，MySQL 的主键自增 ID 是在插入数据的阶段由存储引擎生成的，确保了生成的自增 ID 的唯一性和顺序性。这一机制简化了开发者对主键的管理，并提供了高效的自增 ID 生成方式。

# redis

## 实现一个分布式锁需要考虑哪些
- 互斥性，只有一个线程能够能拿到，redis的setnx
- 防死锁，系统宕机之后这个锁仍然可以拿到，可以用过期时间来做 + 锁续期（任务没完成要继续
- 可重入，获取到锁之后，他自己还能获取到
- 高性能，粒度要合适

弊端：
redis集群是一个AP的架构，不能保证强一致性。因此在master上上锁成功之后，如果master宕机了，而这个锁没还没有同步到slave，slave就变成master了，那么另一个客户端可能再次加锁成功，对业务造成破坏。

因此要用CP的分布式系统来实现锁，zookeeper或者etcd（前者paxos后者raft协议保证

## redis有哪些持久化方案，线上该如何配置

1. RDB
有点
- 基于某个时间点的全量备份，压缩后文件体积小
- 加载RDB文件恢复快
缺点
实时性不够，可能丢失
通过bgsave，需要fork一个子线程，频繁执行成本高

2. AOF
记录的是写后日志。把数据写入内存，然后才开始记录日志，日志里面存储的是redis记录的每一条命令，这些命令是以文本的形式保存的

优点：
根据策略的不同，能够做到几乎不丢失数据。（策略：同步写回，每秒写回，有操作系统控制的写回）
缺点
回放日志慢
日志体积大

线上怎么做？混合来做

## 常用优化手段

1. 生产环境禁用keys命令，因为keys要遍历存储的键值对，生产环境下可能造成阻塞
2. keys需要设置过期时间
3. 禁止批量相同的过期时间（1）雪崩问题 （2）redis删除过期数据的机制。先采集一定量的数据，如果过期数据超过25%， 那么继续采样删除
4. redis也有慢日志查询
5. 减少big key。如果一个key写入的value比较大，那么redis在分配内存时会比较耗时
6. fork耗时严重。为了保证redis数据安全，可能会开启后台RDB和AOF rewrite功能。

## 如何尽可能保证redis中都是热点数据？

考察redis的数据淘汰策略

todo

1. noeviction 这种策略代表不进行数据淘汰
2. random 随机策略，缓存蛮累的时候随机删除一部分
3. volatile-ttl，针对设置了过期时间的数据，越早过期的越先被删除
4. lru。如果数据刚被访问过，那么将来被访问的几率也很高，该算法考虑了数据访问时间
5. lfu。在lru的基础上，除了考虑了时间，还考虑了频次

## 击穿问题

何为击穿？ 大量请求发过来，查询redis没有命中，然后请求又打到mysql上去了

解决方案1：

1. 请求发过来
2. 查询redis(没有命中)
3. 加锁同步查询数据库：（1）加锁，获取到锁才可以执行 （2）再查询一次redis，查询到的话跳到第4步，否则到第3步 （3）查询数据库 （4）将查询结果放到redis （5）释放锁（6）返回

- 这个锁叫做：双重查询锁
- 是否需要加分布式锁而不是上面的线程锁？ 可以加，那样的话只有一个请求会最终请求到mysql；也可以加，这样的话集群有多少台机器，就最多有多少请求击穿。因此不要过度设计，用线程锁解决即可

解决方案2:

热数据永不过期

冷数据设置过期时间

## 缓存雪崩
原因：
1. 一批数据集中过期，导致大量不同请求达到了数据库
2. redis挂掉了

解决方案：
1. 在解决击穿问题的基础上，给数据加上随机过期时间
2. 哨兵模式；高可用部署

## 缓存穿透

大量请求，在redis查不到，在数据库也查不到。可能是有人恶意请求，比如请求一些不存在的资源

解决：
1. 参数校验，比如id为负数了
2. 缓存空对象，记得设置失效时间
3. bloom过滤器。数据库没有的数据放到里面（黑名单模式）

# consul

## Consul 的负载均衡是如何实现的？

当一个服务需要访问其他服务时，它会向 Consul 的 Agent 发送一个服务发现请求，Agent 会返回一个可用的服务地址列表，并根据负载均衡算法选择一个地址进行访问。
Consul 支持多种负载均衡算法，包括轮询、随机、加权轮询、加权随机等

## Consul 的故障恢复是如何实现的？

Consul 的故障恢复是通过 Agent 进程实现的。
当一个服务的健康状态发生变化时，Agent 会将服务的状态信息发送到 Consul 的 Server 上，并通知其他服务进行故障恢复。
如果一个服务无法访问其他服务，它会向 Consul 的 Agent 发送一个故障恢复请求，Agent 会返回一个可用的服务地址列表，并根据负载均衡算法选择一个地址进行访问。

## Consul 的分布式 KV 存储是如何实现的？

Consul 的分布式 KV 存储是通过 Raft 算法实现的。
当一个服务需要存储一些配置信息时，它会向 Consul 的 Agent 发送一个 KV 存储请求，Agent 会将配置信息存储在本地，并将信息发送到 Consul 的 Server 上。
当服务需要读取配置信息时，它会向 Consul 的 Agent 发送一个 KV 读取请求，Agent 会返回存储在本地的配置信息。

## Consul 的事件通知是如何实现的？


Consul 的事件通知是通过 Watcher 机制实现的。
当一个服务需要监听某个事件时，它会向 Consul 的 Agent 发送一个 Watcher 请求，Agent 会将请求发送到 Consul 的 Server 上，并返回一个 Watcher ID。
当事件发生时，Consul 的 Server 会将事件信息发送到所有注册了 Watcher的服务，服务可以根据事件信息进行相应的处理


# 分布式

## 接口幂等性（防止重复提交

前端
1. 提交之后按钮变成灰色，转菊花
2. Post/Redirect/Get
3. token 重复提交时不会产生副作用，提交时候携带后段下发的token
后端
1. 校验唯一性
2. 校验请求时间戳
3. 状态检查，看看是否已经提交过（好比消息中间件的消息id

## MVCC

事务隔离级别的无锁的实现方式，用于提高事务的兵法性能

## XA事务协议
分布式事务是为了解决微服务架构（形式都是分布式系统）中不同节点之间的数据一致性问题。

1. 2阶段提交 2PC，是经典的强一致性的，中心化的原子提交协议。这里说的中心化是指协议中有两类结点：（1）中心化协调者结点coordinator （2）N个参与者partcipant

准备阶段（开启事务
提交阶段（提交事务/回滚事务，如果只有一个参数着正常完成了准备阶段

缺点：（1）提交时候发生网络问题 （2）只要有一个阻塞住了，所有的参与者都会阻塞 （3）协调者挂了，所有参与者都在阻塞

2. 3阶段提交 3PC

在2PC基础上，
（1）在协调者和参与者中，都引入了超时机制
（2）在第一阶段和第二阶段之间插入了一个新的阶段，3PC包含 
CanCOmmit
PreCommit 询问参与者是否可以预提交
DoCommit 正式提交事务/回滚事务

3. TCC补偿事务提交 应用层两阶段提交，所以对代码的侵入性强

需要一个分布式事务协调器；
1. 任务发起者，调用协调器接口，开启事务
2. 任务发起者， 调用参与者的Try接口
3. 任务发起者，调用协调器接口，提交事务
4. 任务发起者，根据前面两步的接口，调用参与者的Confirm或者Cancel

缺点：
1. 侵入性强
2. 代码开发量
3. Confirm和Cancel需要实现幂等
 
## 常见的分布式 ID 实现

1. UUID

虽然都说 UUID 是全球唯一，具备我们前面提到的要求中的第一点，但是很显然不具备全局递增，这种分布式 ID 可读性很差，如果说只是用来记录日志或者不需要人去理解的场景是可以用，但是不适合我们这里说的业务数据的唯一标识。而且这种无序的 UUID 如果作为主键会很严重影响性能。

2. Redis
Redis 有个 incr 的命令，这个命令是能保证原子递增的，在某种程度上也是可以生成全局 ID，不过使用 Redis 有两个问题：

- 不美观，虽然说我们需要的是一个全局 ID，但是 incr 命令是从 1 开始的整型，所以会导致全局 ID 的长度不一致，虽然说也可以用来标识唯一业务数据，但是某些场景也缺少可读性，因为不携带日期信息；
- 依赖 Redis 的高可用，因为 Redis 是基于内存的，为了保证 ID 的不丢失所以需要对 Redis 进行持久化

3. 变形的数据库自增 ID；
设置自增主键时，步长不一致。（该方法不推荐）

4. 推特雪花算法

算法是推特开源的分布式 ID 生成算法，这个算法提供了一个标准的思路，很多公司都参考这个算法做了自己的实现，比较有名的是美团的 Leaf

雪花算法的思想是化整为零，将分布式 ID 的生成分散到每个机房和机器上，采用一个 64 位 long 类型的的结构来表示一个 ID，64 的结构如下所示，第一位符号位 0，然后是 41 位的时间戳（毫秒），接下来的 10 位是机房加机器，最后的 12 位是序列号。

也就是说一毫秒可以取出2^12=4096个
- 生成结果趋势递增，不一定是单调递增
- 因为有时间戳，所以满足自增的要求，同时也具备一定的可读性；
- 化整为零每个服务在各自的机器上可以直接生成唯一 ID，只需要配置好机房和机器编号即可；
- 长度可以根据业务自行调整；
- 缺点是依赖机器的时钟，如果说机器的时钟有问题（时钟回拨问题），会导致生成的 ID 可能会重复，这个需要控制；

时钟回拨的解决方案：

（1）抛异常 （2）发现时钟回拨问题收，等待一下 （3）优化雪花算法，将10位的机器+机房的前三位在拆分出来，做时钟序列，一旦发现时钟回拨了，就给这三位加一

5. 美团的 Leaf——雪花算法的变形；

# 系统设计

## 高并发场景下如何保证接口的幂等性，比如重复下单问题、MQ发送重复消息问题、RPC的调用发因超时重发请求问题

1. 乐观锁实现幂等性。比如给table增加一个版本号，请求中要携带上一次看到的版本号
2. 分布式锁。注意锁的粒度，“只锁自己”
3. token
- 服务端提供获取token的接口，请求之前，客户端需要首先获取token
- 服务端 该token作为key存入redis，注意设置过期时间
- 客户端获取到该token，请求时携带上这个token
- 服务端收到请求之后，查询redis是否有这个token（注意原子性，避免两个请求都查到），有的话立即删除，然后执行逻辑
-

## 二维码登陆要点

- 手机端只有第一次登陆时要求用户输入账号密码（实际上还有设备信息），拿到token之后，通过token继续访问其他接口
- 二维码是有唯一性标识的，它包含了<二维码ID，PC设备信息>两部分内容。是PC端请求服务器之后生成的。
- PC端接收到的二维码，可以是图片，也可以是数据。然后轮询其状态
- 扫码之后，实现了账号ID，二维码ID，PC设备信息三者之间的绑定，服务端返回给手机端一个临时token。这个token是确认登陆时的凭证
- 确认登陆之后，服务端绑定了<二维码ID，设备信息，帐号信息>，同时生成PC端token。
- pc端轮询到token，完成token。

## redis和mysql如何保证双写一致性？
首先需要明确概念：
- 强一致性，任何一次读都能读到最近的一次写的结果
- 弱一致性，数据更新之后，可能临时读取不到最新的结果，但最终会读取到最新的结果

1. 方案一，延迟双删 （弱一致性
先删除缓存，再更新DB，再延迟几秒再去删除一次缓存（二次删除）
弊端：小概率会出现不一致的情况 （有一个请求，读取到旧的DB数据之后，卡住了；在二次删除之后，把旧数据更新到缓存了）
弊端2:耦合程度高，任意的接口都要这么来一次。。。。
2. 方案二，通过MQ异步删除
更新完DB之后，进行一次删除缓存；如果删除失败了，那么向MQ发送一条消息，消费者不断重试删除
3. binlog异步删除
低耦合的解决方案是使用canal，canal伪装成mysql的从机，监听mysql的binlog文件，当数据发生变化的时候发送给MQ。最终消费删除

## 单点登录设计与实现
|单点登录模式|优点|缺点|
|---|---|---|
|共享Cookie|简单方便，用户体验好|根域名需要限制一致； Cookie可能不安全|
|OAuth2.0模式|灵活安全，不受站点限制|成本稍高，需要独立的认证中心|
|跨域设置Cookie|用户体验好，不受站点限制|比较麻烦，Cookie可能不安全|
|客户端模式|用户体验好，不受站点限制|成本极高，需要用户安装客户端应用|

## 调用第三方接口遇到的一些坑

1. 域名访问不到
（1）自己网络有问题 （比如自己开启了代理
（2）对方域名故障，对方服务器为部署，对方开启了白名单
 2. token失效
 根据具体的错误码重新获取或者重试
 3. 超时
 根据具体的错误码重试

 ## 100M内存如何读取10G文本，统计文本数字，拿到最多重复的数字？？

 （1）使用缓冲输入流，每次只读取1M
 （2）使用hashmap，数组（范围确定的情况下），或本地文件

 ## MVCC怎么实现的

 mysql的，给每一行添加了隐藏列 
 - DB_TX_ID       占用着当前列的事务ID
 - DB_ROLL_PTR    老数据的存储指针, 最新的历史数据。指向了已提交
 - row_id

 结合read view实现mvcc ，read view决定了你能看到哪些undo log, 它是乐观锁的一种体现
 - creator_trx_id 当前事务
 - min_trx_id 所有没有未提交事务中最小的那个
 - max_trx_id 未开始事务

 另：
 读未能提交：无需锁，也无需MVCC，直接修改原数据，会出现脏毒
 读已提交：每次查询都会创建ReadView读取数据
 可重复度：在事务第一次读的时候，创建一次ReadView
 串行化：解决幻读，用了表锁

## 如何避免用户重复下单

1. 前端按钮设置为灰色，防止用户多次提交
2. 使用redis的setnx （设置key-value， 过期时间为3～5秒，如果这个key没有值的话，会反回true；否则返回false），那么这个key是什么呢？
可以是用户ID+商品ID等

## 秒杀系统
秒杀系统面临的问题
（1）瞬时并发量大，大量用户会在第一时间进行抢购；
（2）库存少，请求数量远远大于库存数量，只有少部分用户能够秒杀成功

方案
- 访问层-商品页
（1）使用静态页，使用cdn（存储一些css、js之类
（2）秒杀按钮：活动前禁用按钮，单击后禁用按钮，滑动验证码防止羊毛党（一个人控制N台机器），排队体验、提升用户体验
- 多级负载均衡 + 限流 + 自动伸缩   硬件负载均衡器 + nginx + 业务网关 + MQ + 服务器集群 + Redis + 数据库读写分离
- Redis：预热、库存、防重（setnx，key选择为用户ID+商品ID+时间）、加锁

# kafka

## 消息积压了怎么办

增加消费者，因为一个分区只能由一个消费者拉取消息。如果消费者小于分区数可以增加消费者

如果消费者数目等于分区数，可以改写几个消费者，让这个消费者消费消息后重新投递到一个新的topic，新的topic有很多分区

如果是消息格式错误或内容问题导致的消息堆积，将错误消息投递到死信队列 todo

## 保证消息不丢失

1. 消费者要求acks=all，副本数大于等于2，要求至少2个副本在线（ISR>=2），
2. brocker同步刷盘
3. 消费者？没有消费完成就提交了==》自动提交改成手动提交

## 保证只消费一次
接收到了消息，处理完了，但是没来得及提交offset
1. 接收到消息之后，将消息存起来，记录消息的消费状态
2. 处理完成消息，使用redis，setnx （注意过期时间）  推荐
3. 使用唯一键约束

## 如何保证消息队列的高可用

1. rabbitmq，它是基于主从做的集群部署。
部署模式：
单机模式：
普通集群部署模式：不具备高可用。数据只存储了一份
镜像集群模式：具备高可用（只有主结点才可以写数据，从结点只能从主结点同步）。每一台机器都保存了所有信息。
2. kafka


# 如何提高节点的资源利用率， GPU碎片问题
# 大规模节点的Lister、缓存，ETCD优化
# Go BackGround 和 TODO
# 健康检查是谁执行的？
# apiserver的认证方式都有哪些
# 请求到apiserver之后的流程